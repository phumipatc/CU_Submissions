{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/phumipatc/CU_Submissions/blob/master/AI/Sound_to_Dementia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WhzVamIuIaTp"},"source":["# **Dataset: DementiaBank**\n","https://dementia.talkbank.org/\n","\n","\n","English Pitt Corpus: Cookie theft task\n","* https://dementia.talkbank.org/access/English/Pitt.html\n","* Dementia vs control\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5eDNdHdsWZ5s"},"source":["Preparing environment"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"id":"tpRwQWWtWhTQ","outputId":"eac85615-a90f-4695-83d8-ad1897ca4a70","trusted":true},"outputs":[],"source":["%pip install openl3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%pip install nvidia-cudnn-cu11==8.6.0.163 tensorflow==2.12.*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:37:30.598919Z","iopub.status.busy":"2023-06-07T04:37:30.598628Z","iopub.status.idle":"2023-06-07T04:37:30.611561Z","shell.execute_reply":"2023-06-07T04:37:30.610608Z","shell.execute_reply.started":"2023-06-07T04:37:30.598893Z"},"trusted":true},"outputs":[],"source":["address_sample_path = '/kaggle/input/dementia-adress-m-train/train/'\n","address_sample_csv_path = '/kaggle/input/dementia-train-groundtruth/'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nOpJ8W0LI88Q"},"source":["# **Audio Embedding**\n","# OpenL3\n","* https://openl3.readthedocs.io/en/latest/tutorial.html\n","* http://www.justinsalamon.com/uploads/4/3/9/4/4394963/cramer_looklistenlearnmore_icassp_2019.pdf\n","\n","# AudioSet\n","* https://github.com/tensorflow/models/tree/master/research/audioset\n","* Use vggish\n","* Or, https://tfhub.dev/google/vggish/1\n","\n","# Other embedding models\n","* https://tfhub.dev/s?module-type=audio-embedding\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgwjEEILXAFR","outputId":"6528ddcb-7996-44cd-c6d8-be0158776808","trusted":true},"outputs":[],"source":["%pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7pYqONLnrTE","outputId":"63cb63e9-e034-4ffd-b146-3b5d4ef3bd79","trusted":true},"outputs":[],"source":["# need to be run\n","\n","import os\n","\n","address_sample_list = []\n","address_sample_name = []\n","for fName in os.listdir(address_sample_path):\n","#   check if fName is file\n","\tif os.path.isfile(os.path.join(address_sample_path, fName)):\n","\t\taddress_sample_name.append(fName)\n","\t\taddress_sample_list.append(address_sample_path + fName)\n","# print size of list\n","address_sample_name.sort()\n","address_sample_list.sort()\n","print(len(address_sample_list))\n","print(address_sample_name)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Before embedded audio, each audio file need to be at the same length. We are going to pad the audio file"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","\n","# padding the audio file\n","def pad_audio(audio, sr, duration):\n","\tpadding_samples = duration - len(audio)\n","\tif padding_samples <= 0:\n","\t\treturn audio\n","\telse:\n","\t\treturn np.pad(audio, (0, padding_samples), 'constant')\n","\n","def cut_audio(audio, sr, duration):\n","\tif(len(audio) <= duration):\n","\t\treturn pad_audio(audio, sr, duration)\n","\tfrontCut = int((len(audio) - duration)*0.5)\n","\tbackCut = frontCut + duration\n","\treturn audio[frontCut:backCut]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import librosa\n","import gc\n","\n","min_duration = 1e9\n","max_duration = 0\n","mean_duration = 0\n","lenList = []\n","for sample in address_sample_list[:]:\n","\taudio, sr = librosa.load(sample, sr = 8000)\n","#\tprint(audio.shape)\n","\tmin_duration = min(min_duration, len(audio))\n","\tmax_duration = max(max_duration, len(audio))\n","\tmean_duration += len(audio)\n","\tlenList.append(len(audio))\n","mean_duration /= len(address_sample_list)\n","median_duration = np.median(lenList)\n","print(min_duration, max_duration, mean_duration, median_duration)\n","\n","del lenList\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33CIJGn9IV2A","outputId":"04426165-b634-4f7b-d7f5-24efd9d85392","trusted":true},"outputs":[],"source":["import pickle\n","import openl3\n","import gc\n","\n","for i in range(0,len(address_sample_name)):\n","\tprint(str(i) + ': processing ' + address_sample_name[i])\n","\tsample = address_sample_list[i]\n","\taudio, sr = librosa.load(sample, sr=8000)\n","\tif len(audio.shape) > 1:\n","\t\taudio = audio.mean(axis=1)\n","\taudio = cut_audio(audio, sr, int(median_duration))\n","\ttry:\n","\t\tembedding, timestamps = openl3.get_audio_embedding(audio, sr)\n","\t\ttry:\n","\t\t\twith open(address_sample_name[i].split('.')[0] + '.pkl' , 'wb') as f:\n","\t\t\t\tpickle.dump((embedding, timestamps), f)\n","\t\t\tdel f\n","\t\texcept Exception as error:\n","\t\t\tprint('error saving pickle file for ' + address_sample_name[i])\n","\t\t\tprint(error)\n","\t\t\tbreak\n","\t\tdel embedding\n","\t\tdel timestamps\n","\texcept Exception as error:\n","\t\tprint('error getting audio embedding from' + address_sample_name[i])\n","\t\tprint(error)\n","\t\tbreak\n","\tdel sample\n","\tdel audio\n","\tdel sr\n","\tgc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8fPBxKnaJat0"},"source":["# **Classification**\n","# Classics\n","* https://scikit-learn.org/stable/supervised_learning.html\n","* Logistic regression, Support Vector Classification, Decision Tree, Random Forest, Neural Net, AdaBoost, Na√Øve Bayes\n","* https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n","\n","# Classification heads\n","* https://www.isca-speech.org/archive/pdfs/interspeech_2021/gauder21_interspeech.pdf\n","* Neural networks - Conv1D (k=1), Conv1D (k=3), Global. Average\n","* https://www.isca-speech.org/archive/pdfs/interspeech_2021/wang21ca_interspeech.pdf-Neural networks - Conv - Conv1D - Softmax\n","* Others\n","* https://www.tensorflow.org/tutorials/images/transfer_learning#add_a_classification_head"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gc\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:37:30.615976Z","iopub.status.busy":"2023-06-07T04:37:30.615681Z","iopub.status.idle":"2023-06-07T04:37:30.652667Z","shell.execute_reply":"2023-06-07T04:37:30.651723Z","shell.execute_reply.started":"2023-06-07T04:37:30.615953Z"},"trusted":true},"outputs":[],"source":["# need to be run\n","\n","import pandas as pd\n","\n","# Get dataFrame\n","address_sample_original_df = pd.read_csv(address_sample_csv_path + \"training-groundtruth.csv\")\n","address_sample_clean_df = address_sample_original_df\n","del address_sample_original_df\n","#address_sample_clean_df = address_sample_original_df.dropna().drop_duplicates()\n","\n","# Cleaning Process\n","\n","## Drop other columns\n","address_sample_clean_df.drop(['age', 'gender', 'educ', 'mmse'], axis=1, inplace=True)\n","\n","## In dx column, change \"Control\" to 0 and \"ProbableAD\" to 1\n","address_sample_clean_df['dx'] = address_sample_clean_df['dx'].apply(lambda x: 0 if x == \"Control\" else 1)\n","\n","address_sample_clean_df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:37:30.654715Z","iopub.status.busy":"2023-06-07T04:37:30.654298Z","iopub.status.idle":"2023-06-07T04:37:30.755228Z","shell.execute_reply":"2023-06-07T04:37:30.754295Z","shell.execute_reply.started":"2023-06-07T04:37:30.654684Z"},"trusted":true},"outputs":[],"source":["# need to be run\n","\n","import os\n","\n","address_sample_name = []\n","for fName in os.listdir(address_sample_path):\n","#   check if fName is file\n","\tif os.path.isfile(os.path.join(address_sample_path, fName)):\n","\t\taddress_sample_name.append(fName)\n","# print size of list\n","address_sample_name.sort()\n","print(len(address_sample_name))\n","# print(address_sample_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import librosa\n","from sklearn.preprocessing import normalize\n","import matplotlib.pyplot as plt\n","\n","def extract_features(embedding, sr):\n","    # we will extract 4 features from each embedding\n","\t# 1. MFCC (Mel-Frequency Cepstral Coefficients)\n","\t# 2. Chromagram, spectral bandwidth, centroid repeatedly\n","\t# 3. Short-Time Fourier Transform\n","\t# 4. Zero Crossing Rate\n","\t\n","\t# 1. MFCC (Mel-Frequency Cepstral Coefficients)\n","\t# parameter y is the audio time series\n","\t# parameter sr is the sampling rate of y\n","\t# parameter n_mfcc is the number of MFCCs to return\n","\tmfcc = librosa.feature.mfcc(y=embedding, sr=sr, n_mfcc=128)\n","\n","\t# 2. Chromagram, spectral bandwidth, centroid repeatedly\n","\t# parameter y is the audio time series\n","\t# parameter sr is the sampling rate of y\n","\tchroma_stft = librosa.feature.chroma_stft(y=embedding, sr=sr)\n","\tspectral_bandwidth = librosa.feature.spectral_bandwidth(y=embedding, sr=sr)\n","\tspectral_centroid = librosa.feature.spectral_centroid(y=embedding, sr=sr)\n","\n","\t# 3. Short-Time Fourier Transform\n","\t# parameter y is the audio time series\n","\t# parameter n_fft is the length of the FFT window\n","\t# parameter hop_length is the number of samples between successive frames\n","\tstft = np.abs(librosa.stft(embedding, n_fft=255, hop_length=512))\n","\n","\t# 4. Zero Crossing Rate\n","\t# parameter y is the audio time series\n","\tzero_crossing_rate = librosa.feature.zero_crossing_rate(embedding)\n","\n","\t# spectral_contrast = librosa.feature.spectral_contrast(y=embedding, sr=sr, fmin=100, n_bands=10)\n","\n","\timage = np.array(spectral_bandwidth)\n","\timage = np.append(image, spectral_centroid, axis=0)\n","\timage = np.append(image, chroma_stft, axis=0)\n","\timage = np.append(image, zero_crossing_rate, axis=0)\n","\timage = np.append(image, zero_crossing_rate, axis=0)\n","\n","\tfor i in range(0,7):\n","\t\timage = np.append(image, spectral_bandwidth, axis=0)\n","\t\timage = np.append(image, spectral_centroid, axis=0)\n","\t\timage = np.append(image, chroma_stft, axis=0)\n","\t\timage = np.append(image, zero_crossing_rate, axis=0)\n","\t\timage = np.append(image, zero_crossing_rate, axis=0)\n","\n","\t# stack all the features together\n","\tfinal = np.dstack((mfcc, image, stft))\n","\n","\t# print(mfcc.shape, image.shape, stft.shape, final.shape)\n","\n","\t# show result of the features\n","\tplt.figure(figsize=(10, 4))\n","\tlibrosa.display.specshow(librosa.power_to_db(final[:, :, 0], ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n","\tplt.colorbar(format='%+2.0f dB')\n","\tplt.title('MFCC')\n","\tplt.tight_layout()\n","\tplt.show()\n","\n","\t# plt.figure(figsize=(10, 4))\n","\tlibrosa.display.specshow(librosa.power_to_db(final[:, :, 1], ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n","\tplt.colorbar(format='%+2.0f dB')\n","\tplt.title('Spectral Bandwidth')\n","\tplt.tight_layout()\n","\tplt.show()\n","\n","\t# plt.figure(figsize=(10, 4))\n","\tlibrosa.display.specshow(librosa.power_to_db(final[:, :, 2], ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n","\tplt.colorbar(format='%+2.0f dB')\n","\tplt.title('Short-Time Fourier Transform')\n","\tplt.tight_layout()\n","\tplt.show()\n","\n","\t# return the features\n","\treturn final\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:37:30.757973Z","iopub.status.busy":"2023-06-07T04:37:30.757222Z","iopub.status.idle":"2023-06-07T04:37:54.710786Z","shell.execute_reply":"2023-06-07T04:37:54.709764Z","shell.execute_reply.started":"2023-06-07T04:37:30.757938Z"},"trusted":true},"outputs":[],"source":["#need to be run for training model\n","\n","import pickle\n","import gc\n","import numpy as np\n","\n","result = []\n","y_train = []\n","\n","# address_sample_number = len(address_sample_name)\n","address_sample_number = 22\n","\n","#read each pickle file and append to result\n","for i in range(0,address_sample_number):\n","\tif(address_sample_clean_df['cate'][i] == 'test'):\n","\t\tcontinue\n","\tprint(str(i) + ': reading ' + address_sample_name[i].split('.')[0] + '.pkl')\n","\twith open(address_sample_name[i].split('.')[0] + '.pkl', 'rb') as f:\n","\t\tembedding, timestamps = pickle.load(f)\n","\t\t# print(np.shape(embedding))\n","\t\tresult.append(extract_features(embedding, timestamps))\n","\t\ty_train.append(address_sample_clean_df['dx'][i])\n","\t\tdel embedding\n","\t\tdel timestamps\n","\t\tgc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# shuffle the result\n","from sklearn.utils import shuffle\n","result, y_train = shuffle(result, y_train, random_state=42)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Classic - Logistic Regressing**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train = np.reshape(result, (np.shape(result)[0], -1))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.shape(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","clf = LogisticRegression(max_iter = 150, random_state=0).fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# save model \n","import pickle\n","pickle.dump(clf, open('logistic_regression_model.sav', 'wb'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**CNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:37:57.754869Z","iopub.status.busy":"2023-06-07T04:37:57.754527Z","iopub.status.idle":"2023-06-07T04:37:59.240418Z","shell.execute_reply":"2023-06-07T04:37:59.239478Z","shell.execute_reply.started":"2023-06-07T04:37:57.754842Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","X_train = np.array(result)\n","y_train = np.array(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:37:59.607038Z","iopub.status.busy":"2023-06-07T04:37:59.606584Z","iopub.status.idle":"2023-06-07T04:37:59.614368Z","shell.execute_reply":"2023-06-07T04:37:59.613272Z","shell.execute_reply.started":"2023-06-07T04:37:59.606996Z"},"trusted":true},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train = X_train.astype(np.float16)\n","\n","X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:38:03.616484Z","iopub.status.busy":"2023-06-07T04:38:03.616111Z","iopub.status.idle":"2023-06-07T04:38:03.819235Z","shell.execute_reply":"2023-06-07T04:38:03.818039Z","shell.execute_reply.started":"2023-06-07T04:38:03.616436Z"},"trusted":true},"outputs":[],"source":["del result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:38:07.994960Z","iopub.status.busy":"2023-06-07T04:38:07.994006Z","iopub.status.idle":"2023-06-07T04:38:08.098529Z","shell.execute_reply":"2023-06-07T04:38:08.097477Z","shell.execute_reply.started":"2023-06-07T04:38:07.994920Z"},"trusted":true},"outputs":[],"source":["gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:38:38.789058Z","iopub.status.busy":"2023-06-07T04:38:38.788701Z","iopub.status.idle":"2023-06-07T04:38:45.788889Z","shell.execute_reply":"2023-06-07T04:38:45.787950Z","shell.execute_reply.started":"2023-06-07T04:38:38.789023Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n","tf.config.experimental.set_memory_growth(gpu_devices[0], True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:38:45.791816Z","iopub.status.busy":"2023-06-07T04:38:45.790789Z","iopub.status.idle":"2023-06-07T04:38:48.273392Z","shell.execute_reply":"2023-06-07T04:38:48.272645Z","shell.execute_reply.started":"2023-06-07T04:38:45.791782Z"},"trusted":true},"outputs":[],"source":["CNNmodel = tf.keras.models.Sequential()\n","\n","CNNmodel.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n","CNNmodel.add(layers.MaxPooling2D((2, 2)))\n","CNNmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","CNNmodel.add(layers.MaxPooling2D((2, 2)))\n","CNNmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\n","CNNmodel.add(layers.MaxPooling2D((2, 2)))\n","CNNmodel.add(layers.Conv2D(512, (3, 3), activation='relu'))\n","CNNmodel.add(layers.MaxPooling2D((2, 2)))\n","CNNmodel.add(layers.Flatten())\n","CNNmodel.add(layers.Dropout(0.7))\n","CNNmodel.add(layers.Dense(1024, activation='relu'))\n","CNNmodel.add(layers.Dense(1, activation='sigmoid'))\n","\n","CNNmodel.compile(optimizer='adam',\n","                 loss='binary_crossentropy',\n","                 metrics=['accuracy'])\n","\n","CNNmodel.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del CNNmodel"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device_name = tf.test.gpu_device_name()\n","\n","if \"GPU\" not in device_name:\n","    print(\"GPU device not found\")\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-07T04:39:19.570195Z","iopub.status.busy":"2023-06-07T04:39:19.569320Z","iopub.status.idle":"2023-06-07T04:39:41.034155Z","shell.execute_reply":"2023-06-07T04:39:41.032580Z","shell.execute_reply.started":"2023-06-07T04:39:19.570149Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import LambdaCallback\n","\n","# train model\n","history = CNNmodel.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, shuffle=True)\n","\n","# save model\n","CNNmodel.save('cnn_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot training history\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim([0.5, 1])\n","plt.legend(loc='lower right')\n","plt.show()\n","\n","plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label = 'val_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.ylim([0, 5])\n","plt.legend(loc='lower right')\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Testing model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#optional\n","\n","del X_train\n","del y_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del clf"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#optional\n","\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Load Testing Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# need to be run\n","\n","import pandas as pd\n","\n","# Get dataFrame\n","address_sample_original_df = pd.read_csv(address_sample_csv_path + \"training-groundtruth.csv\")\n","address_sample_clean_df = address_sample_original_df\n","del address_sample_original_df\n","#address_sample_clean_df = address_sample_original_df.dropna().drop_duplicates()\n","\n","# Cleaning Process\n","\n","## Drop other columns\n","address_sample_clean_df.drop(['age', 'gender', 'educ', 'mmse'], axis=1, inplace=True)\n","\n","## In dx column, change \"Control\" to 0 and \"ProbableAD\" to 1\n","address_sample_clean_df['dx'] = address_sample_clean_df['dx'].apply(lambda x: 0 if x == \"Control\" else 1)\n","\n","address_sample_clean_df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# need to be run\n","\n","import os\n","\n","address_sample_name = []\n","for fName in os.listdir(address_sample_path):\n","#   check if fName is file\n","\tif os.path.isfile(os.path.join(address_sample_path, fName)):\n","\t\taddress_sample_name.append(fName)\n","# print size of list\n","address_sample_name.sort()\n","print(len(address_sample_name))\n","# print(address_sample_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#need to be run for training model\n","\n","import pickle\n","import gc\n","\n","X_test = []\n","y_test = []\n","\n","address_sample_number = len(address_sample_name)\n","\n","#read each pickle file and append to result\n","for i in range(0,address_sample_number):\n","\tif(address_sample_clean_df['cate'][i] == 'train'):\n","\t\tcontinue\n","\tprint(str(i) + ': reading ' + address_sample_name[i].split('.')[0] + '.pkl')\n","\ttry:\n","\t\twith open(address_sample_name[i].split('.')[0] + '.pkl', 'rb') as f:\n","\t\t\ttry:\n","\t\t\t\tembedding, timestamps = pickle.load(f)\n","\t\t\t\tX_test.append(embedding)\n","\t\t\t\ty_test.append(address_sample_clean_df['dx'][i])\n","\t\t\t\tdel embedding\n","\t\t\t\tdel timestamps\n","\t\t\t\tgc.collect()\n","\t\t\texcept Exception as error:\n","\t\t\t\tprint('error loading pickle file for ' + address_sample_name[i].split('.')[0] + '.pkl')\n","\t\t\t\tprint(error)\n","\texcept Exception as error:\n","\t\tprint('error reading pickle file for ' + address_sample_name[i].split('.')[0] + '.pkl')\n","\t\tprint(error)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Testing Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_test = np.reshape(X_test, (np.shape(X_test)[0],-1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# optional IF model is trained and need to be loaded\n","\n","import pickle\n","\n","clf = pickle.load(open('logistic_regression_modelHalf.sav', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test Logistic Regression\n","\n","y_pred = clf.predict(X_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Testing CNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gc\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load CNN model\n","\n","import tensorflow as tf\n","\n","model = tf.keras.models.load_model('cnn_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Test CNN model\n","\n","y_pred = model.predict(X_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Show Accuracy Score**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.round(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(y_test, y_pred.round())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Showing Confusion Matrix below**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# confusion matrix\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","cm = confusion_matrix(y_test, y_pred.round())\n","sns.heatmap(cm, annot=True, fmt='g')\n","plt.xlabel('Predicted')\n","plt.ylabel('Truth')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
