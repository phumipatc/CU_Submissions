{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phumipatc/CU_Submissions/blob/master/AI/Sound_to_Dementia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WhzVamIuIaTp"
      },
      "source": [
        "# **Dataset: DementiaBank**\n",
        "https://dementia.talkbank.org/\n",
        "\n",
        "\n",
        "English Pitt Corpus: Cookie theft task\n",
        "* https://dementia.talkbank.org/access/English/Pitt.html\n",
        "* Dementia vs control\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDNdHdsWZ5s"
      },
      "source": [
        "Preparing environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpRwQWWtWhTQ",
        "outputId": "eac85615-a90f-4695-83d8-ad1897ca4a70"
      },
      "outputs": [],
      "source": [
        "%pip install openl3\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib\n",
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw2s6M-bqPCX",
        "outputId": "915369c3-042a-4949-f8e4-b72dd48532db"
      },
      "outputs": [],
      "source": [
        "def tryImportColab():\n",
        "  try:\n",
        "    import google.colab\n",
        "    return True\n",
        "  except ImportError:\n",
        "    return False\n",
        "\n",
        "runningInColab = tryImportColab()\n",
        "runningInColab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ALY9RTKX7w2",
        "outputId": "49006fad-92af-4298-f363-45d8956b8f21"
      },
      "outputs": [],
      "source": [
        "if(runningInColab):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nOpJ8W0LI88Q"
      },
      "source": [
        "# **Audio Embedding**\n",
        "# OpenL3\n",
        "* https://openl3.readthedocs.io/en/latest/tutorial.html\n",
        "* http://www.justinsalamon.com/uploads/4/3/9/4/4394963/cramer_looklistenlearnmore_icassp_2019.pdf\n",
        "\n",
        "# AudioSet\n",
        "* https://github.com/tensorflow/models/tree/master/research/audioset\n",
        "* Use vggish\n",
        "* Or, https://tfhub.dev/google/vggish/1\n",
        "\n",
        "# Other embedding models\n",
        "* https://tfhub.dev/s?module-type=audio-embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZgwjEEILXAFR",
        "outputId": "6528ddcb-7996-44cd-c6d8-be0158776808"
      },
      "outputs": [],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "fOfq7MptgR4n",
        "outputId": "146fd783-1b79-4c2c-caca-63f01c717476"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "address_sample_csv_path = 'sound-dementia-data/ADReSS-M-train/'\n",
        "if runningInColab:\n",
        "\taddress_sample_csv_path = 'drive/MyDrive/' + address_sample_csv_path\n",
        "\n",
        "# Get dataFrame\n",
        "address_sample_original_df = pd.read_csv(address_sample_csv_path + \"training-groundtruth.csv\")\n",
        "address_sample_clean_df = address_sample_original_df.dropna().drop_duplicates()\n",
        "\n",
        "# Cleaning Process\n",
        "## In gender col, change \"Female\" to 0 and \"Male\" to 1\n",
        "address_sample_clean_df['gender'] = address_sample_clean_df['gender'].apply(lambda x: 0 if x == \"Female\" else 1)\n",
        "## In dx column, change \"Control\" to 0 and \"ProbableAD\" to 1\n",
        "address_sample_clean_df['dx'] = address_sample_clean_df['dx'].apply(lambda x: 0 if x == \"Control\" else 1)\n",
        "\n",
        "# Drop non-numeric columns\n",
        "numeric_df = address_sample_clean_df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate correlation matrix\n",
        "numeric_df.corr()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7pYqONLnrTE",
        "outputId": "63cb63e9-e034-4ffd-b146-3b5d4ef3bd79"
      },
      "outputs": [],
      "source": [
        "import openl3\n",
        "import os\n",
        "import soundfile as sf\n",
        "\n",
        "address_sample_path = 'sound-dementia-data/ADReSS-M-train/train/'\n",
        "if runningInColab:\n",
        "  address_sample_path = 'drive/MyDrive/' + address_sample_path\n",
        "address_sample_list = []\n",
        "for fName in os.listdir(address_sample_path):\n",
        "  address_sample_list.append(address_sample_path + fName)\n",
        "address_sample_list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before embedded audio, each audio file need to be at the same length. We are going to pad the audio file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# padding the audio file\n",
        "def pad_audio(audio, sr, duration):\n",
        "\tpadding_samples = int(duration*sr) - len(audio)\n",
        "\tif padding_samples <= 0:\n",
        "\t\treturn audio\n",
        "\telse:\n",
        "\t\treturn np.pad(audio, (0, padding_samples), 'constant')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_duration = 0\n",
        "for sample in address_sample_list:\n",
        "  audio, sr = sf.read(sample)\n",
        "  max_duration = max(max_duration, len(audio) / sr)\n",
        "max_duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33CIJGn9IV2A",
        "outputId": "04426165-b634-4f7b-d7f5-24efd9d85392"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "for sample in address_sample_list:\n",
        "  audio, sr = sf.read(sample)\n",
        "  if len(audio.shape) > 1:\n",
        "    audio = audio.mean(axis=1)\n",
        "  audio = pad_audio(audio, sr, max_duration)\n",
        "  try:\n",
        "    embedding, timestamps = openl3.get_audio_embedding(audio, sr)\n",
        "# save each embedding and timestamp to a file using pickle\n",
        "    with open(address_sample_path + 'embedded_sample/' + sample + '.pkl', 'wb') as f:\n",
        "      pickle.dump((embedding, timestamps), f)\n",
        "  except:\n",
        "    print('error in ' + sample)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8fPBxKnaJat0"
      },
      "source": [
        "# **Classification**\n",
        "# Classics\n",
        "* https://scikit-learn.org/stable/supervised_learning.html\n",
        "* Logistic regression, Support Vector Classification, Decision Tree, Random Forest, Neural Net, AdaBoost, Na√Øve Bayes\n",
        "* https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
        "\n",
        "# Classification heads\n",
        "* https://www.isca-speech.org/archive/pdfs/interspeech_2021/gauder21_interspeech.pdf\n",
        "* Neural networks - Conv1D (k=1), Conv1D (k=3), Global. Average\n",
        "* https://www.isca-speech.org/archive/pdfs/interspeech_2021/wang21ca_interspeech.pdf-Neural networks - Conv - Conv1D - Softmax\n",
        "* Others\n",
        "* https://www.tensorflow.org/tutorials/images/transfer_learning#add_a_classification_head"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SA1UbgKTmGq1"
      },
      "source": [
        "**Classic - Logistic Regressing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqGAemlbmPOz"
      },
      "outputs": [],
      "source": [
        "# using logistic regressing to predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# make X 2D by its row is each sample and 3 column is each feature\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(result)):\n",
        "  X.append(result[i][0][0])\n",
        "  y.append(address_sample_clean_df['dx'].iloc[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save model \n",
        "import pickle\n",
        "pickle.dump(clf, open('logistic_regression_model.sav', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Showing Confusion Matrix below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNTlaCt8NKQKNONnoX5wYSt",
      "collapsed_sections": [
        "8fPBxKnaJat0"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
